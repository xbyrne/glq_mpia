{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710b23f7",
   "metadata": {
    "id": "710b23f7"
   },
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5599263",
   "metadata": {
    "id": "b5599263"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e7208",
   "metadata": {
    "id": "aa0e7208"
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04849ae9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39820,
     "status": "ok",
     "timestamp": 1661936654853,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "04849ae9",
    "outputId": "991e7920-8f10-4288-b0ed-a9e8f918ff19"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c74b80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65079,
     "status": "ok",
     "timestamp": 1661936719919,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "01c74b80",
    "outputId": "fc9bd74f-812b-43fb-ac56-eaafeef1df49"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Reshape, Concatenate, MaxPooling2D as MP,\\\n",
    "RandomFlip, RandomRotation, RandomCrop, RandomTranslation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3bab7",
   "metadata": {
    "id": "8bd3bab7"
   },
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a532cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbf78e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2372,
     "status": "ok",
     "timestamp": 1661936722280,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "9dfbf78e"
   },
   "outputs": [],
   "source": [
    "fl = np.load('/content/drive/MyDrive/images.npz')\n",
    "imgs = fl['imgs']\n",
    "ids = fl['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_imgs(imgs, setting=3):\n",
    "    \"\"\"\n",
    "    A normalisation function, with several settings.\n",
    "    Default is to normalise each object to the brightest pixel in the brightest band\n",
    "        This erases brightness information but preserves colour information\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if setting==0:\n",
    "        # Global normalisation to the range [0,1]\n",
    "        nimgs = imgs - np.min(imgs) # Now lowest value is 0, max is like 1e5\n",
    "        nimgs /= np.max(nimgs) # Now in range [0,1]\n",
    "\n",
    "    elif setting==1: # Bandwise normalisation\n",
    "        nimgs = imgs / np.max(imgs, axis=(0,1,2))\n",
    "\n",
    "    elif setting==2: # Gaussian normalisation\n",
    "        nimgs = imgs - np.mean(imgs, axis=0) # Subtracting 'mean' object\n",
    "        nimgs /= np.std(nimgs, axis=0) # Dividing by 'std' object\n",
    "\n",
    "    elif setting==3: # Object-wise normalisation\n",
    "        nimgs = imgs / np.max(imgs, axis=(1,2,3))[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "    \n",
    "    return nimgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56a791",
   "metadata": {
    "id": "0e56a791"
   },
   "source": [
    "---\n",
    "## Training Model\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416369f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1661936724868,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "4416369f",
    "outputId": "28afb231-4ecc-4771-9ff1-83db4c043c3d"
   },
   "outputs": [],
   "source": [
    "# Augmentor\n",
    "def load_augmentor(translate_px=2):\n",
    "    input_images = Input(shape=(28,28,5), name='img_input')\n",
    "    x = RandomCrop(24,24, name='cropper')(input_images)\n",
    "    x = RandomFlip(name='flipper')(x)\n",
    "    x = RandomTranslation(translate_px/24, translate_px/24,\n",
    "                        fill_mode='wrap',\n",
    "                        name='translator')(x)\n",
    "    augmented_images = RandomRotation(.5, name='rotator')(x)\n",
    "    augmentor = Model(input_images, augmented_images,\n",
    "                    name='augmentor')\n",
    "    return augmentor\n",
    "\n",
    "# Encoder Base, with inputs randomly cropped to shape (24,24,5)\n",
    "def load_encoder():\n",
    "    augmented_images = Input(shape=(24,24,5), name='augmented_input')\n",
    "    x = Conv2D(256, 5, activation='relu',\n",
    "            name='Conv2D_0')(augmented_images)\n",
    "    x = MP(pool_size=2)(x)\n",
    "    x = Conv2D(512, 3, activation='relu',\n",
    "            name='Conv2D_1')(x)\n",
    "    x = MP(pool_size=2)(x)\n",
    "    x = Conv2D(1024, 3, activation='relu',\n",
    "            name='Conv2D_2')(x)\n",
    "    x = MP(pool_size=2)(x)\n",
    "    features = Reshape((1024,),\n",
    "                    name='Reshape')(x)\n",
    "    encoder = Model(augmented_images, features,\n",
    "                name='encoder')\n",
    "    return encoder\n",
    "\n",
    "# Projection Head\n",
    "def load_projector():\n",
    "    features = Input(shape=(1024,), name='features')\n",
    "    x = Dense(512, activation='relu',\n",
    "            name='Dense_0')(features)\n",
    "    x = Dense(128, activation='relu',\n",
    "            name='Dense_1')(x)\n",
    "    projection = Dense(64,\n",
    "                    name='Dense_2')(x)\n",
    "    projector = Model(features, projection,\n",
    "                    name='projector')\n",
    "    return projector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b4f72",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def boltz_matrix(normed_mini_batch, temp=1):\n",
    "    \"\"\"\n",
    "    An intermediate step in calculating the loss for a given batch\n",
    "    Inputs: A mini-batch of (normalised) vectors z_i\n",
    "            A temperature parameter, default=1\n",
    "    Output: A matrix with the values B_ij = exp(sim(z_i, z_j)/temp) if i!=j, 0 if i==j.\n",
    "                This matrix has the shape (2*batch_size, 2*batch_size)\n",
    "    \"\"\"\n",
    "    raw_bm =  tf.math.exp(\n",
    "        tf.linalg.matmul(normed_mini_batch, normed_mini_batch, transpose_b=True) / temp\n",
    "    ) # exp(sim(z_i, z_j)/temp) forall i, j\n",
    "    return tf.linalg.set_diag(raw_bm, tf.zeros_like(normed_mini_batch[:,0])) # zeroing out where i==j\n",
    "\n",
    "@tf.function\n",
    "def contrastive_loss(mini_batch, temp=1): # Minibatch(i) has shape (batch_size*2, projection_dim)\n",
    "    \"\"\"\n",
    "    Calculates contrastive loss for a given mini-batch\n",
    "    Inputs: A mini-batch of N-dimensional vectors output by the projector of the CNN\n",
    "            A temperature parameter, default=1\n",
    "    Output: The scalar contrastive loss for that mini-batch\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(mini_batch)[0] // 2 # Should be even anyway\n",
    "    normed_mini_batch, _ = tf.linalg.normalize(mini_batch, axis=1) # Loss only needs angles\n",
    "    boltz_mat = boltz_matrix(normed_mini_batch, temp=temp)\n",
    "    positive_boltzs = tf.linalg.diag_part(tf.roll(boltz_mat,batch_size, 0)) # Positive samples\n",
    "    boltz_norms = tf.math.reduce_sum(boltz_mat, axis=0)\n",
    "    return tf.math.reduce_mean(\n",
    "        -tf.math.log(tf.math.divide(positive_boltzs, boltz_norms))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8eac6",
   "metadata": {},
   "source": [
    "### Contrastive Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contrastor(Model):\n",
    "    def __init__(self, augmentor, encoder, projector, temperature=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.augmentor=augmentor\n",
    "        self.encoder=encoder\n",
    "        self.projector=projector\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='contrastive loss')\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward Pass\n",
    "            projection1 = self.projector(self.encoder(self.augmentor(data)))\n",
    "            projection2 = self.projector(self.encoder(self.augmentor(data)))\n",
    "            mini_batch = Concatenate(axis=0)([projection1, projection2])\n",
    "            \n",
    "            cl = contrastive_loss(mini_batch, temp=self.temperature)\n",
    "\n",
    "        grads = tape.gradient(cl, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        self.loss_tracker.update_state(cl)\n",
    "        return{'loss': self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grizY_contr = Contrastor(\n",
    "    load_augmentor(),\n",
    "    load_encoder(),\n",
    "    load_projector(),\n",
    "    temperature=.015\n",
    ")\n",
    "grizY_contr.compile(\n",
    "    optimizer=optimizers.SGD(\n",
    "        learning_rate=1e-4,\n",
    "        momentum=1e-4),\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = grizY_contr.fit(\n",
    "    normalise_imgs(imgs),\n",
    "    batch_size=128,\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='loss',\n",
    "            mode='min',\n",
    "            patience=5,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z4mywllr99qj",
   "metadata": {
    "id": "Z4mywllr99qj"
   },
   "source": [
    "---\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70720fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grizY_enc = grizY_contr.encoder # Encoder of above trained model\n",
    "\n",
    "# Forward passing the original images\n",
    "encoded_imgs = grizY_enc(\n",
    "    normalise_imgs(imgs[:,2:-2,2:-2,:])\n",
    "    ).numpy()\n",
    "encoded_imgs = np.array([enc_img / np.linalg.norm(enc_img) for enc_img in encoded_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c08161",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP().fit(encoded_imgs)\n",
    "points = embedding.embedding_\n",
    "np.savez_compressed('./gdrive/MyDrive/embedding.npz',\n",
    "                    points = embedding.embedding_,\n",
    "                    ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2befeca",
   "metadata": {
    "id": "dYUA6l6bK2Ew"
   },
   "source": [
    "The embedding reveals several clusters, of which one is of particular interest: the tiny cluster just west of the major continent, nicknamed \"Sylt\". There are 12 objects here, of which 8 are known (spectroscopically confirmed) high-redshift quasars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784b197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fl = np.load('./embedding.npz')\n",
    "ids = fl['ids']\n",
    "points = fl['points']\n",
    "x = points[:,0]\n",
    "y = points[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b61cf46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.5, 6.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fg, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(x,y,\n",
    "            s=1,\n",
    "            c='k'\n",
    "           )\n",
    "isin_sylt = (x>4.8)&(x<5.2)\n",
    "ax.axvline(4.8, c='g')\n",
    "ax.axvline(5.2, c='g')\n",
    "ax.set_xlim([4.5,6])\n",
    "ax.set_ylim([4.5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d23218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_of_interest = ids[isin_sylt]\n",
    "np.savez_compressed('./sylt_ids.npz',\n",
    "                    ids=objs_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9e765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "b5599263",
    "aa0e7208",
    "ST4ThrNrLPeP"
   ],
   "name": "trainer.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
