{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710b23f7",
   "metadata": {
    "id": "710b23f7"
   },
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5599263",
   "metadata": {
    "id": "b5599263"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e7208",
   "metadata": {
    "id": "aa0e7208"
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04849ae9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39820,
     "status": "ok",
     "timestamp": 1661936654853,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "04849ae9",
    "outputId": "991e7920-8f10-4288-b0ed-a9e8f918ff19"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c74b80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65079,
     "status": "ok",
     "timestamp": 1661936719919,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "01c74b80",
    "outputId": "fc9bd74f-812b-43fb-ac56-eaafeef1df49"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Reshape, Concatenate, MaxPooling2D as MP,\\\n",
    "RandomFlip, RandomRotation, RandomCrop, RandomTranslation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3bab7",
   "metadata": {
    "id": "8bd3bab7"
   },
   "source": [
    "### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a532cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbf78e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2372,
     "status": "ok",
     "timestamp": 1661936722280,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "9dfbf78e"
   },
   "outputs": [],
   "source": [
    "fl = np.load('/content/drive/MyDrive/images.npz')\n",
    "imgs = fl['imgs']\n",
    "ids = fl['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_imgs(imgs, setting=3):\n",
    "    \"\"\"\n",
    "    A normalisation function, with several settings.\n",
    "    Default is to normalise each object to the brightest pixel in the brightest band\n",
    "        This erases brightness information but preserves colour information\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if setting==0:\n",
    "        # Global normalisation to the range [0,1]\n",
    "        nimgs = imgs - np.min(imgs) # Now lowest value is 0, max is like 1e5\n",
    "        nimgs /= np.max(nimgs) # Now in range [0,1]\n",
    "\n",
    "    elif setting==1: # Bandwise normalisation\n",
    "        nimgs = imgs / np.max(imgs, axis=(0,1,2))\n",
    "\n",
    "    elif setting==2: # Gaussian normalisation\n",
    "        nimgs = imgs - np.mean(imgs, axis=0) # Subtracting 'mean' object\n",
    "        nimgs /= np.std(nimgs, axis=0) # Dividing by 'std' object\n",
    "\n",
    "    elif setting==3: # Object-wise normalisation\n",
    "        nimgs = imgs / np.max(imgs, axis=(1,2,3))[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "    \n",
    "    return nimgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56a791",
   "metadata": {
    "id": "0e56a791"
   },
   "source": [
    "---\n",
    "## Training Model\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416369f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1661936724868,
     "user": {
      "displayName": "Alex Byrne",
      "userId": "16624359446890840019"
     },
     "user_tz": -120
    },
    "id": "4416369f",
    "outputId": "28afb231-4ecc-4771-9ff1-83db4c043c3d"
   },
   "outputs": [],
   "source": [
    "# Augmentor\n",
    "def load_augmentor(translate_px=2):\n",
    "    input_images = Input(shape=(28,28,5), name='img_input')\n",
    "    x = RandomCrop(24,24, name='cropper')(input_images)\n",
    "    x = RandomFlip(name='flipper')(x)\n",
    "    x = RandomTranslation(translate_px/24, translate_px/24,\n",
    "                        fill_mode='wrap',\n",
    "                        name='translator')(x)\n",
    "    augmented_images = RandomRotation(.5, name='rotator')(x)\n",
    "    augmentor = Model(input_images, augmented_images,\n",
    "                    name='augmentor')\n",
    "    return augmentor\n",
    "\n",
    "# Encoder Base, with inputs randomly cropped to shape (24,24,5)\n",
    "def load_encoder():\n",
    "    augmented_images = Input(shape=(24,24,5), name='augmented_input')\n",
    "    x = Conv2D(256, 5, activation='relu',\n",
    "            name='Conv2D_0')(augmented_images)\n",
    "    x = MP(pool_size=2)(x)\n",
    "    x = Conv2D(512, 3, activation='relu',\n",
    "            name='Conv2D_1')(x)\n",
    "    x = MP(pool_size=2)(x)\n",
    "    x = Conv2D(1024, 3, activation='relu',\n",
    "            name='Conv2D_2')(x)\n",
    "    x = MP(pool_size=2)(x)\n",
    "    features = Reshape((1024,),\n",
    "                    name='Reshape')(x)\n",
    "    encoder = Model(augmented_images, features,\n",
    "                name='encoder')\n",
    "    return encoder\n",
    "\n",
    "# Projection Head\n",
    "def load_projector():\n",
    "    features = Input(shape=(1024,), name='features')\n",
    "    x = Dense(512, activation='relu',\n",
    "            name='Dense_0')(features)\n",
    "    x = Dense(128, activation='relu',\n",
    "            name='Dense_1')(x)\n",
    "    projection = Dense(64,\n",
    "                    name='Dense_2')(x)\n",
    "    projector = Model(features, projection,\n",
    "                    name='projector')\n",
    "    return projector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b4f72",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034a665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def boltz_matrix(normed_mini_batch, temp=1):\n",
    "    \"\"\"\n",
    "    An intermediate step in calculating the loss for a given batch\n",
    "    Inputs: A mini-batch of (normalised) vectors z_i\n",
    "            A temperature parameter, default=1\n",
    "    Output: A matrix with the values B_ij = exp(sim(z_i, z_j)/temp) if i!=j, 0 if i==j.\n",
    "                This matrix has the shape (2*batch_size, 2*batch_size)\n",
    "    \"\"\"\n",
    "    raw_bm =  tf.math.exp(\n",
    "        tf.linalg.matmul(normed_mini_batch, normed_mini_batch, transpose_b=True) / temp\n",
    "    ) # exp(sim(z_i, z_j)/temp) forall i, j\n",
    "    return tf.linalg.set_diag(raw_bm, tf.zeros_like(normed_mini_batch[:,0])) # zeroing out where i==j\n",
    "\n",
    "@tf.function\n",
    "def contrastive_loss(mini_batch, temp=1): # Minibatch(i) has shape (batch_size*2, projection_dim)\n",
    "    \"\"\"\n",
    "    Calculates contrastive loss for a given mini-batch\n",
    "    Inputs: A mini-batch of N-dimensional vectors output by the projector of the CNN\n",
    "            A temperature parameter, default=1\n",
    "    Output: The scalar contrastive loss for that mini-batch\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(mini_batch)[0] // 2 # Should be even anyway\n",
    "    normed_mini_batch, _ = tf.linalg.normalize(mini_batch, axis=1) # Loss only needs angles\n",
    "    boltz_mat = boltz_matrix(normed_mini_batch, temp=temp)\n",
    "    positive_boltzs = tf.linalg.diag_part(tf.roll(boltz_mat,batch_size, 0)) # Positive samples\n",
    "    boltz_norms = tf.math.reduce_sum(boltz_mat, axis=0)\n",
    "    return tf.math.reduce_mean(\n",
    "        -tf.math.log(tf.math.divide(positive_boltzs, boltz_norms))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8eac6",
   "metadata": {},
   "source": [
    "### Contrastive Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contrastor(Model):\n",
    "    def __init__(self, augmentor, encoder, projector, temperature=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.augmentor=augmentor\n",
    "        self.encoder=encoder\n",
    "        self.projector=projector\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='contrastive loss')\n",
    "        self.temperature = temperature\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward Pass\n",
    "            projection1 = self.projector(self.encoder(self.augmentor(data)))\n",
    "            projection2 = self.projector(self.encoder(self.augmentor(data)))\n",
    "            mini_batch = Concatenate(axis=0)([projection1, projection2])\n",
    "            \n",
    "            cl = contrastive_loss(mini_batch, temp=self.temperature)\n",
    "\n",
    "        grads = tape.gradient(cl, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        self.loss_tracker.update_state(cl)\n",
    "        return{'loss': self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grizY_contr = Contrastor(\n",
    "    load_augmentor(),\n",
    "    load_encoder(),\n",
    "    load_projector(),\n",
    "    temperature=.015\n",
    ")\n",
    "grizY_contr.compile(\n",
    "    optimizer=optimizers.SGD(\n",
    "        learning_rate=1e-4,\n",
    "        momentum=1e-4),\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = grizY_contr.fit(\n",
    "    normalise_imgs(imgs),\n",
    "    batch_size=128,\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='loss',\n",
    "            mode='min',\n",
    "            patience=5,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z4mywllr99qj",
   "metadata": {
    "id": "Z4mywllr99qj"
   },
   "source": [
    "---\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70720fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grizY_enc = grizY_contr.encoder # Encoder of above trained model\n",
    "\n",
    "# Forward passing the original images\n",
    "encoded_imgs = grizY_enc(\n",
    "    normalise_imgs(imgs[:,2:-2,2:-2,:])\n",
    "    ).numpy()\n",
    "encoded_imgs = np.array([enc_img / np.linalg.norm(enc_img) for enc_img in encoded_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c08161",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP().fit(encoded_imgs)\n",
    "points = embedding.embedding_\n",
    "np.savez_compressed('./gdrive/MyDrive/embedding.npz',\n",
    "                    points = embedding.embedding_,\n",
    "                    ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2befeca",
   "metadata": {
    "id": "dYUA6l6bK2Ew"
   },
   "source": [
    "The embedding reveals several clusters, of which two are of particular interest:\n",
    "1. The small strip to the North of the major continent, labelled \"Svalbard\". Many of these objects have strange extensions, so could potentially be lensed quasars.\n",
    "2. The tiny cluster just west of the major continent, labelled \"atoll\". There are 12 objects here, of which 8 are known (spectroscopically confirmed) high-redshift quasars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fl = np.load('./embedding.npz')\n",
    "ids = fl['ids']\n",
    "points = fl['points']\n",
    "x = points[:,0]\n",
    "y = points[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61cf46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots(figsize=(7,7))\n",
    "ax.scatter(x,y,\n",
    "            s=3,\n",
    "            c='k'\n",
    "           )\n",
    "isin_svalbard = y>12.5\n",
    "ax.axhline(12.5, c='r')\n",
    "isin_atoll = (x>4.8)&(x<5.2)\n",
    "ax.axvline(4.8, c='g')\n",
    "ax.axvline(5.2, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_of_interest = ids[isin_svalbard|isin_atoll]\n",
    "np.savez_compressed('./objs_of_interest.npz',\n",
    "                    ids=objs_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57140c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "b5599263",
    "aa0e7208",
    "ST4ThrNrLPeP"
   ],
   "name": "trainer.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
